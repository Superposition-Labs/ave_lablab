{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to Agent1):\n",
      "\n",
      "Find potential peers for the task: 'Develop a machine learning model for natural language processing'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Error running agent Agent1: Completions.create() got an unexpected keyword argument 'openai_api_key'\n",
      "Task: Develop a machine learning model for natural language processing\n",
      "Initial Agent: Agent1\n",
      "Connections formed:\n",
      "No connections formed.\n"
     ]
    }
   ],
   "source": [
    "# autogen_example.py\n",
    "\n",
    "import os\n",
    "import random\n",
    "import dotenv\n",
    "from typing import List, Annotated\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "import autogen\n",
    "from autogen import AssistantAgent, UserProxyAgent\n",
    "from autogen.cache import Cache\n",
    "from nb_executor import NotebookExecutor\n",
    "\n",
    "from protocol import SocialGraph, find_potential_peers\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# Mockup data\n",
    "AGENTS = {\n",
    "    \"Agent1\": {\"links\": [\"Agent2\", \"Agent3\", \"Agent4\"], \"skills\": [\"Python\", \"Data Analysis\"]},\n",
    "    \"Agent2\": {\"links\": [\"Agent1\", \"Agent3\", \"Agent5\"], \"skills\": [\"Java\", \"Machine Learning\"]},\n",
    "    \"Agent3\": {\"links\": [\"Agent1\", \"Agent2\", \"Agent4\"], \"skills\": [\"Python\", \"NLP\"]},\n",
    "    \"Agent4\": {\"links\": [\"Agent1\", \"Agent3\", \"Agent5\"], \"skills\": [\"C++\", \"Computer Vision\"]},\n",
    "    \"Agent5\": {\"links\": [\"Agent2\", \"Agent4\"], \"skills\": [\"JavaScript\", \"Web Development\"]},\n",
    "}\n",
    "\n",
    "# Initialize the social graph\n",
    "social_graph = SocialGraph(AGENTS)\n",
    "\n",
    "# LLM Configuration\n",
    "llm_config = {\n",
    "    \"config_list\": [{\n",
    "    \"openai_api_key\": os.getenv(\"OPENAI_API_KEY\"),\n",
    "    \"model\": \"gpt-4o-mini\",\n",
    "}],\n",
    "    \"timeout\": 120,\n",
    "}\n",
    "\n",
    "# Define a dictionary to hold our agents\n",
    "agents = {}\n",
    "\n",
    "# Function to create agents\n",
    "def create_agent(agent_id: str):\n",
    "    system_message = f\"You are {agent_id}. Your task is to find potential peers for a given task.\"\n",
    "    chatbot = AssistantAgent(\n",
    "        name=agent_id,\n",
    "        system_message=system_message,\n",
    "        llm_config=llm_config,\n",
    "    )\n",
    "\n",
    "    # Create a UserProxyAgent instance\n",
    "    user_proxy = UserProxyAgent(\"user_proxy\", \n",
    "                                code_execution_config={\"work_dir\": \"./work\", \"use_docker\": False},\n",
    "                                is_termination_msg=lambda x: x.get(\"content\", \"\") and (x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\") or x.get(\"content\", \"\") == \"\"),\n",
    "    human_input_mode=\"NEVER\",\n",
    "    max_consecutive_auto_reply=10,)\n",
    "\n",
    "\n",
    "    # Register the find_potential_peers function\n",
    "    @user_proxy.register_for_execution()\n",
    "    @chatbot.register_for_llm(description=\"Find potential peers for a given task.\")\n",
    "    def find_peers(\n",
    "        task_description: Annotated[str, \"Description of the task\"],\n",
    "        agent_id: Annotated[str, \"ID of the agent\"],\n",
    "        search_depth: Annotated[int, \"Depth of search in the social graph\"] = 2,\n",
    "    ) -> List[str]:\n",
    "        return find_potential_peers(\n",
    "            task_description, agent_id, social_graph, search_depth\n",
    "        )\n",
    "\n",
    "    agents[agent_id] = {\n",
    "        \"chatbot\": chatbot,\n",
    "        \"user_proxy\": user_proxy,\n",
    "    }\n",
    "\n",
    "# Create agents for each agent in AGENTS\n",
    "for agent_id in AGENTS.keys():\n",
    "    create_agent(agent_id)\n",
    "\n",
    "def propagate_request(initial_agent_id: str, task: str, max_hops: int = 2):\n",
    "    visited = set()\n",
    "    current_agents = [initial_agent_id]\n",
    "    connections = []\n",
    "\n",
    "    for hop in range(max_hops):\n",
    "        next_agents = []\n",
    "        for agent_id in current_agents:\n",
    "            if agent_id in visited:\n",
    "                continue\n",
    "            visited.add(agent_id)\n",
    "\n",
    "            agent = agents[agent_id][\"chatbot\"]\n",
    "            user_proxy = agents[agent_id][\"user_proxy\"]\n",
    "\n",
    "            # Start the conversation\n",
    "            with Cache.disk() as cache:\n",
    "                try:\n",
    "                    res = user_proxy.initiate_chat(\n",
    "                        agent,\n",
    "                        message=f\"Find potential peers for the task: '{task}'\",\n",
    "                        cache=cache,\n",
    "                    )\n",
    "                    result = res.chat_history[-1][\"content\"]\n",
    "                except Exception as e:\n",
    "                    print(f\"Error running agent {agent_id}: {e}\")\n",
    "                    continue\n",
    "\n",
    "            # Parse the result to get chosen peers\n",
    "            chosen_peers = result.strip().split(', ')\n",
    "\n",
    "            for peer in chosen_peers:\n",
    "                if peer in visited:\n",
    "                    continue\n",
    "                if peer in AGENTS.keys():\n",
    "                    path = social_graph.get_path(agent_id, peer)\n",
    "                    if path:\n",
    "                        connections.append((agent_id, peer, path))\n",
    "                        if peer not in visited:\n",
    "                            next_agents.append(peer)\n",
    "\n",
    "        current_agents = next_agents\n",
    "\n",
    "    return connections\n",
    "\n",
    "# Run the simulation\n",
    "task = \"Develop a machine learning model for natural language processing\"\n",
    "initial_agent_id = \"Agent1\"\n",
    "connections = propagate_request(initial_agent_id, task)\n",
    "\n",
    "print(f\"Task: {task}\")\n",
    "print(f\"Initial Agent: {initial_agent_id}\")\n",
    "print(\"Connections formed:\")\n",
    "if connections:\n",
    "    for connection in connections:\n",
    "        print(f\"{connection[0]} -> {connection[1]} (Path: {' -> '.join(connection[2])})\")\n",
    "else:\n",
    "    print(\"No connections formed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ave-NDLfIIYq-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
